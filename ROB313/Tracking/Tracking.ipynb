{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: L'advantage de MeanShift :\n",
    "    1) il y a moins de calcul;\n",
    "    2) le temps d'éxecution est petit\n",
    "    3) il peut suivre l'objet rapidement\n",
    "   L'inconvénient est qu'il ne peut pas suivre l'objet précisément. Si l'objet se deplace très rapidement, le fenetre perd son objet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\t# Backproject the model histogram roi_hist onto the \n",
    "\t# current image hsv, i.e. dst(x,y) = roi_hist(hsv(0,x,y))\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # apply meanshift to dst to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw a blue rectangle on the current image\n",
    "        r,c,h,w = track_window\n",
    "        frame_tracked = cv2.rectangle(frame, (r,c), (r+h,c+w), (255,0,0) ,2)\n",
    "        cv2.imshow('Sequence',frame_tracked)\n",
    "\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Je trouve que dans l'image de rétroprojection les pixels de la porte ont les valeur plus élevés que les pixels de tasse. Donc, il perd son objet quand il suit la tasse. Pour amélioer, je change le canal de HSV de canal H(hue) à S(saturation).\n",
    "    roi_hist = cv2.calcHist([hsv_roi],[1],mask,[180],[0,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "#roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "\n",
    "#Q2\n",
    "roi_hist = cv2.calcHist([hsv_roi],[1],mask,[180],[0,180])\n",
    "\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\t# Backproject the model histogram roi_hist onto the \n",
    "\t# current image hsv, i.e. dst(x,y) = roi_hist(hsv(0,x,y))\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        #Q2 display for result \n",
    "        cv2.imshow('Dis ',dst)\n",
    "        \n",
    "        # apply meanshift to dst to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw a blue rectangle on the current image\n",
    "        r,c,h,w = track_window\n",
    "        frame_tracked = cv2.rectangle(frame, (r,c), (r+h,c+w), (255,0,0) ,2)\n",
    "        cv2.imshow('Sequence',frame_tracked)\n",
    "\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Pour calculer l'orientation du gradient, il faut calculer la direction horizontale et la direction verticale avec deux coeurs. Ensuite, j'utilise la fonction cv2.magnitude() pour calculer le norm du gradient. Puis, je peinte les pixels qui sont moins que 50 avec la couleur rouge. Donc il y a cinq image affichantes : 1) \"first image\", 2) \"sequence image\", 3)\"orientation du gradient\", 4)\"norm du gradient\", 5)\"orientation\" (image avec mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[1],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\t# Backproject the model histogram roi_hist onto the \n",
    "\t# current image hsv, i.e. dst(x,y) = roi_hist(hsv(0,x,y))\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # apply meanshift to dst to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw a blue rectangle on the current image\n",
    "        r,c,h,w = track_window\n",
    "        frame_tracked = cv2.rectangle(frame, (r,c), (r+h,c+w), (255,0,0) ,2)\n",
    "        cv2.imshow('Sequence',frame_tracked)\n",
    "\n",
    "        ##Q3\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)        \n",
    "        #orientation x\n",
    "        kernel = np.array([[-1, 0, 1],[-1, 0, 1],[-1, 0, 1]])\n",
    "        Ix = cv2.filter2D(frame_gray,-1,kernel)\n",
    "        Ix = np.array(Ix, np.float32)\n",
    "        #oritentaion y\n",
    "        kernel = np.array([[-1, -1, -1],[0, 0, 0],[1, 1, 1]])\n",
    "        Iy = cv2.filter2D(frame_gray,-1,kernel)\n",
    "        Iy = np.array(Iy, np.float32)\n",
    "        #angle calculation\n",
    "        angle = cv2.phase(Ix,Iy,angleInDegrees=True)\n",
    "        #norm of gradient\n",
    "        norm = cv2.magnitude(Ix, Iy)\n",
    "        #add mask\n",
    "        thresh = 50\n",
    "        _, mask = cv2.threshold(norm, thresh, 255, cv2.THRESH_BINARY)\n",
    "        orient = np.zeros((angle.shape[0], angle.shape[1], 3),dtype=np.float32)\n",
    "        orient[(mask == 0)] = np.array([0, 0, 1])#fill with red color\n",
    "        #display of result\n",
    "        cv2.imshow('Orientation du gradient',angle)\n",
    "        cv2.imshow('Norm du gradient',norm)\n",
    "        cv2.imshow('Orientation',orient)\n",
    "        \n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Pour achievez la transformation hough,je définis quatre fonctions:\n",
    "    1)orientation_gradient(image): calculez l'orientation du gradient, returnez l'angle (dégrée)\n",
    "    2)RTable(image,ref): il faut un image grey et un point de réference. D'about il calcule l'orientation du gradient avec la fonction orientation_gradient(image). Ensuite, il construit une RTable pour ceux qui ont la même angle avec un vecteur entre ce point et le point de réference.\n",
    "    3)detection(image,rTable): il faut utiliser le résultat de fonction RTable(image,ref). Il trouve la similarité entre cet image et la RTable de l'autre image par l'orientation du gradient.Pour tous les points qui ont la même orientation, augmentez la graphique de vote.\n",
    "    4)Hmax(hough): selectez la position plus possible par choisir arg max H(x), retournez la valeur maximale et la position(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "    \n",
    "def orientation_gradient(image):\n",
    "    Image = image\n",
    "    #orientation x\n",
    "    kernel = np.array([[-1, 0, 1],[-1, 0, 1],[-1, 0, 1]])\n",
    "    Ix = cv2.filter2D(image,-1,kernel)\n",
    "    Ix = np.array(Ix, np.float32)\n",
    "    #oritentaion y\n",
    "    kernel = np.array([[-1, -1, -1],[0, 0, 0],[1, 1, 1]])\n",
    "    Iy = cv2.filter2D(image,-1,kernel)\n",
    "    Iy = np.array(Iy, np.float32)\n",
    "    #angle calculation\n",
    "    angle = cv2.phase(Ix,Iy,angleInDegrees=True)\n",
    "    angle = angle*180/np.pi #change to degree\n",
    "    return angle\n",
    "\n",
    "def RTable(image,ref):#need gray image and reference point(x,y)\n",
    "    Image = image\n",
    "    edge = cv2.Canny(Image,10,1000)#find the line in the image\n",
    "    angle = orientation_gradient(image)\n",
    "    rTable = defaultdict(list)\n",
    "    for (i,j),value in np.ndenumerate(edge):\n",
    "        rTable[angle[i,j]].append((ref[0]-i,ref[1]-j))#store the vector in each angle\n",
    "    return rTable\n",
    "\n",
    "def detection(image,rTable):#construct the vote map H(x)\n",
    "    Image = image\n",
    "    edge = cv2.Canny(image,10,1000)#find the line in the image\n",
    "    angle = orientation_gradient(image)\n",
    "\n",
    "    hough = np.zeros(image.shape)\n",
    "    for (i,j),value in np.ndenumerate(edge):\n",
    "        for r in rTable[angle[i,j]]:\n",
    "            x = r[0] + i\n",
    "            y = r[1] + j\n",
    "            if x < hough.shape[0] and y < hough.shape[1]:\n",
    "                hough[i,j] += 1 #suppose weight is 1\n",
    "    return hough\n",
    "\n",
    "def Hmax(hough):#find the arg max H(x)\n",
    "    #x = np.argmax(hough, axis=1)\n",
    "    #y =  np.max(hough, axis=1)\n",
    "    #print(x,y)\n",
    "    #return x,y\n",
    "    indices = hough.ravel().argsort()[-1:]\n",
    "    indices = (np.unravel_index(i, hough.shape) for i in indices)\n",
    "    #print([(hough[i], i) for i in indices])\n",
    "    return [(hough[i], i) for i in indices]\n",
    "                \n",
    "## Test Code        \n",
    "  \n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "##Q4\n",
    "referenceImage = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "sobelX = cv2.Sobel(referenceImage,cv2.CV_64F,1,0)#gradient X\n",
    "sobelY = cv2.Sobel(referenceImage,cv2.CV_64F,0,1)#gradient Y\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "RefSobelCombined = cv2.bitwise_or(sobelX,sobelY)\n",
    "referencePoint = [RefSobelCombined.shape[0]/2, RefSobelCombined.shape[1]/2]#choose center of reference image as the reference point\n",
    "rTable = RTable(RefSobelCombined,referencePoint)\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        ##Q4\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        sobelX = cv2.Sobel(frame_gray,cv2.CV_64F,1,0)#gradient X\n",
    "        sobelY = cv2.Sobel(frame_gray,cv2.CV_64F,0,1)#gradient Y\n",
    "\n",
    "        sobelX = np.uint8(np.absolute(sobelX))\n",
    "        sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "        sobelCombined = cv2.bitwise_or(sobelX,sobelY)\n",
    "        hough = detection(sobelCombined,rTable)\n",
    "        m =  Hmax(hough)\n",
    "        y = [pt[1][0] for pt in m][0]\n",
    "        x = [pt[1][1] for pt in m][0]\n",
    "        cv2.imshow('Hough',hough)\n",
    "\n",
    "        frame_tracked = cv2.rectangle(frame, (int(x-0.5*h),int(y-0.5*w)), (int(x+0.5*h),int(y+0.5*w)), (255,0,0) ,2)\n",
    "        #cv2.imshow('Sequence',frame_tracked)\n",
    "\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "    \n",
    "def orientation_gradient(image):\n",
    "    Image = image\n",
    "    #orientation x\n",
    "    kernel = np.array([[-1, 0, 1],[-1, 0, 1],[-1, 0, 1]])\n",
    "    Ix = cv2.filter2D(image,-1,kernel)\n",
    "    Ix = np.array(Ix, np.float32)\n",
    "    #oritentaion y\n",
    "    kernel = np.array([[-1, -1, -1],[0, 0, 0],[1, 1, 1]])\n",
    "    Iy = cv2.filter2D(image,-1,kernel)\n",
    "    Iy = np.array(Iy, np.float32)\n",
    "    #angle calculation\n",
    "    angle = cv2.phase(Ix,Iy,angleInDegrees=True)\n",
    "    angle = angle*180/np.pi #change to degree\n",
    "    return angle\n",
    "\n",
    "def RTable(image,ref):#need gray image and reference point(x,y)\n",
    "    Image = image\n",
    "    edge = cv2.Canny(Image,10,1000)#find the line in the image\n",
    "    angle = orientation_gradient(image)\n",
    "    rTable = defaultdict(list)\n",
    "    for (i,j),value in np.ndenumerate(edge):\n",
    "        rTable[angle[i,j]].append((ref[0]-i,ref[1]-j))#store the vector in each angle\n",
    "    return rTable\n",
    "\n",
    "def detection(image,rTable):#construct the vote map H(x)\n",
    "    Image = image\n",
    "    edge = cv2.Canny(image,10,1000)#find the line in the image\n",
    "    angle = orientation_gradient(image)\n",
    "\n",
    "    hough = np.zeros(image.shape)\n",
    "    for (i,j),value in np.ndenumerate(edge):\n",
    "        for r in rTable[angle[i,j]]:\n",
    "            x = r[0] + i\n",
    "            y = r[1] + j\n",
    "            if x < hough.shape[0] and y < hough.shape[1]:\n",
    "                hough[i,j] += 1 #suppose weight is 1\n",
    "    return hough\n",
    "\n",
    "def Hmax(hough):#find the arg max H(x)\n",
    "    #x = np.argmax(hough, axis=1)\n",
    "    #y =  np.max(hough, axis=1)\n",
    "    #print(x,y)\n",
    "    #return x,y\n",
    "    indices = hough.ravel().argsort()[-1:]\n",
    "    indices = (np.unravel_index(i, hough.shape) for i in indices)\n",
    "    #print([(hough[i], i) for i in indices])\n",
    "    return [(hough[i], i) for i in indices]\n",
    "                \n",
    "## Test Code        \n",
    "  \n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "##Q4\n",
    "referenceImage = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "referencePoint = [referenceImage.shape[0]/2, referenceImage.shape[1]/2]#choose center of reference image as the reference point\n",
    "rTable = RTable(referenceImage,referencePoint)\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        ##Q4\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hough = detection(frame_gray,rTable)\n",
    "\n",
    "        # apply meanshift to dst to get the new location\n",
    "        ret, track_window = cv2.meanShift(hough, track_window, term_crit)\n",
    "\n",
    "        # Draw a blue rectangle on the current image\n",
    "        r,c,h,w = track_window\n",
    "        frame_tracked = cv2.rectangle(frame, (r,c), (r+h,c+w), (255,0,0) ,2)\n",
    "        cv2.imshow('Sequence',frame_tracked)\n",
    "\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
